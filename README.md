# AWS-Realtime-Data-Pipeline-Kinesis-DynamoDB
## Real-time Data Pipeline for Network Optimization
### Project Overview:
This project demonstrates a real-time data management solution on the AWS Cloud, designed to ingest streaming data into Amazon Kinesis, process it with AWS Lambda, and store it in Amazon DynamoDB for future analysis. This architecture provides a scalable, flexible, and cost-effective foundation for organizations requiring immediate insights from high-volume data streams.

### Problem Statement:
A company building communication networks in rapidly growing, underserved markets, needs to optimize its network topologies continuously. This requires deploying an effective architecture for NoSQL-based data warehousing built from real-time data generated by their innovative communication hardware. The challenge is to efficiently collect, process, and store this real-time data in a way that is scalable, flexible, and cost-effective, enabling future analytical capabilities.

### Architectural Solution:
The solution leverages key AWS serverless and managed services to create a robust real-time data pipeline:

### Data Generation (Simulated):

A Python script (data_generator.py) simulates the continuous generation of network performance data (e.g., link IDs, speeds, latencies).

This script pushes the simulated data directly into an Amazon Kinesis Data Stream.

### Data Ingestion & Streaming (Amazon Kinesis Data Stream):

Amazon Kinesis Data Stream acts as a highly scalable and durable real-time data ingestion service. It reliably captures and stores gigabytes of data per second from thousands of sources, making it ideal for continuous data feeds from network hardware.

### Real-time Processing (AWS Lambda):

An AWS Lambda function (kinesis_processor_lambda.py) is configured as a consumer of the Kinesis Data Stream.

Lambda automatically scales to process incoming records from the stream. The function extracts relevant data points from each Kinesis record, performs any necessary transformations or validations, and prepares the data for storage.

### Data Warehousing (Amazon DynamoDB):

Amazon DynamoDB, a fully managed, high-performance NoSQL database, serves as the data warehouse for the processed real-time data.

DynamoDB's flexible schema, single-digit millisecond performance at any scale, and serverless nature make it an excellent choice for storing the network topology data, allowing for efficient retrieval and analysis for optimization.

### Automated Deployment (AWS Serverless Application Model - SAM):

The entire backend infrastructure (Kinesis Stream, Lambda Function, DynamoDB Table, and necessary IAM roles) is defined and deployed using an AWS SAM template (template.yaml). This ensures consistent, repeatable, and version-controlled deployments.

### Key Architectural Decisions (KADs):
Kinesis for Real-time Ingestion: Chosen for its ability to handle high-throughput, low-latency data streams, providing a reliable buffer before processing.

Lambda for Stream Processing: Selected for its serverless nature, auto-scaling capabilities, and cost-effectiveness for processing individual records from Kinesis without managing servers.

DynamoDB for NoSQL Data Warehousing: Opted for its managed service benefits, high performance for read/write operations, and flexible schema to accommodate evolving network data structures.

AWS SAM for Infrastructure as Code: Utilized to define the entire serverless application stack declaratively, enabling automated deployments and versioning of the infrastructure.

### Diagrams:
Architectural diagrams for this project would typically include:

System Context Diagram (C4 Model Level 1): Showing the data sources (simulated hardware), the AWS Cloud, and the analytics consumers.

Container Diagram (C4 Model Level 2): Detailing Kinesis, Lambda, and DynamoDB as key components, along with the data flow between them.

Sequence Diagram: Illustrating the step-by-step flow of data from generation through Kinesis, Lambda processing, and storage in DynamoDB.

Deployment Diagram: Visualizing the deployment of these AWS services within the cloud environment.

(You would place your actual diagram image files in the diagrams/ folder.)

### Code Examples:
Illustrative code snippets for simulating data generation, the Kinesis processing Lambda function, and the AWS SAM template for infrastructure provisioning are provided in their respective folders:

data-generator/: Python script to send data to Kinesis.

kinesis-processor-lambda/: Python code for the AWS Lambda function.

infrastructure/: AWS SAM template (template.yaml) for deploying the AWS resources.

### Outcomes & Benefits:
This project successfully demonstrates a robust and efficient real-time data pipeline on AWS, providing:

Scalability: Automatically scales to handle vast amounts of incoming real-time network data.

Cost-Effectiveness: Leverages serverless and managed services, optimizing costs based on actual usage.

Flexibility: Adaptable to various data sources and future analytical requirements for network optimization.

Reduced Operational Burden: Minimizes the need for manual server management and maintenance.

Foundation for Analytics: Provides a structured, real-time data store in DynamoDB, ready for immediate analysis to optimize network topologies.

This solution empowers organizations like TELEMAX to make data-driven decisions swiftly, improving their services and operational efficiency.

### Why Work With Me?
I deliver architectural solutions that bridge technical vision with business goals, enabling organizations to innovate faster and operate more efficiently. My focus is on creating architectures that are not only powerful today but are also adaptable for the challenges of tomorrow.

### Contact:
Feel free to connect with me to discuss architectural challenges or opportunities:

LinkedIn: [https://www.linkedin.com/in/krunalnayak]

Email: [Krunalnayak49@gmail.com]
